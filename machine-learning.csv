Reinforcement Learning vs Supervised Learning, Learning with a critic vs learning with a teacher
\(TFIDF_{ij} \) term \(i \) document \(j\), \( \frac{log(TF_{ij} + 1)}{log(\frac{n_{docs}}{n_{docs \text{ with term } i}})}\)
Logistic function; a sigmoid function, \(\frac{1}{1+e^{-x}}\)
Sofmax of vector \(a\), \(S(a) = [\frac{e^{a_1}}{\sum_{c=1}^C e^{a_c}}  \dots \frac{e^{a_C}}{\sum_{c=1}^C e^{a_c}} ]\) where \(a\) is called logits or generalized log odds
Logit, \(\sigma^{-1}(p) = \log(\frac{p}{1-p})\)

Weak supervision, Using metadata as labels for data; e.g. hashtags associated with a picture
Paradigms of self-supervision in CV, 1. Invariance (function of input should equal function of perturbed input); 2. Pretext tasks (predicting properties)
Invariance, \(f(g(x)) = f(x)\)
Equivariance, \(f(g(x)) = g(f(x))\)
Topology (informal), Geometric notion of neighborhood without notion of distance
Manifold (informal), Topological space which resembles a Euclidean space locally; near each point.

LIME explanation, "\( \xi(x) = argmin_{g' \in G} \mathcal{L}(f, g', \pi_x) + \Omega(g')\) with
- \(f\), the original model
- \(G\) the class of possible, interpretable surrogate models
- \(\Omega(g)\), a measure of complexity for \(g \in G\)
- \(\pi_x(z)\) a proximity measure of \(z\) wrt data point \(x\)
- \(\mathcal{L}(f, g, \pi_x)\) a measure of how unfaithful a \(g \in G\) is to \(f\) in the locality defined by \(\pi_x\)
"

Shapley value, "\( \psi_i(v) = \sum_{S \subset N \setminus \{i\}} {|N| \choose 1, |S|, n-|S|-1}^{-1} v(S \cup \{i\}) - v(S) \)
for player \(i \in N\) wrt payoff \(v\)
"

Kinds of self-supervision, "1. Pretext task
2. Invariance"